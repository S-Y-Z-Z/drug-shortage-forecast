{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearnex加速\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import sklearnex\n",
    "sklearnex.patch_sklearn()\n",
    "\n",
    "# 引用ARIMA模型\n",
    "# 读取csv文件\n",
    "\n",
    "df = pd.read_csv('data.csv', encoding='gbk').to_numpy()\n",
    "df = df.astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "max_value = np.max(df)\n",
    "min_value = np.min(df)\n",
    "scalar = max_value - min_value\n",
    "df = list(map(lambda x: x / scalar, df))\n",
    "df = np.array(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据集分为训练集和测试集\n",
    "train = df[:int(0.95*(len(df)))]\n",
    "test = df[int(0.95*(len(df))):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用ARIMA进行预测\n",
    "# order=(p,d,q) p:自回归阶数 d:差分阶数 q:移动平均阶数\n",
    "model = ARIMA(train, order=(3, 3, 30))\n",
    "\n",
    "model_fit = model.fit()\n",
    "\n",
    "# 预测测试集\n",
    "ARM_yhat = model_fit.predict(len(train), len(train)+len(test)-2, typ='levels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = 7\n",
    "matrix = np.zeros((df.size-windows, windows+1))\n",
    "for i in range(df.size-windows):    # 生成矩阵\n",
    "    matrix[i] = df[i:i+windows+1].T\n",
    "# 将数据集分为训练集和测试集\n",
    "train_m = matrix[:int(0.95*(len(matrix)))]\n",
    "test_m = matrix[int(0.95*(len(matrix))):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用XGBoost进行预测\n",
    "# 将数据格式转换成DMatrix格式\n",
    "train_dmatrix = xgb.DMatrix(data=train_m[:, :-1], label=train_m[:, -1])\n",
    "test_dmatrix = xgb.DMatrix(data=test_m[:, :-1], label=test_m[:, -1])\n",
    "\n",
    "# 设置参数\n",
    "params = {'booster': 'gbtree',    # 使用gbtree,可选项gbtree,gbliner\n",
    "          'objective': 'reg:linear',  # 使用线性回归,可选项reg:linear,reg:logistic\n",
    "          'eval_metric': 'rmse',  # 评估函数,回归问题rmse,分类问题error\n",
    "          'gamma': 0.1,  # 指定了节点分裂所需的最小损失函数下降值\n",
    "          'min_child_weight': 1.1,   # 指定了叶子节点最小的样本权重和\n",
    "          'max_depth': 500,  # 树的最大深度\n",
    "          'lambda': 10,   # 权重的L2正则化项\n",
    "          'subsample': 0.5,   # 训练每棵树时使用的数据占全部训练集的比例\n",
    "          'colsample_bytree': 0.5,   # 训练每棵树时使用的特征占全部特征的比例\n",
    "          'colsample_bylevel': 0.5,   # 训练每棵树时使用的特征占全部特征的比例\n",
    "          'eta': 0.1,     # 学习率\n",
    "          'tree_method': 'auto',  # 使用的建树方法,可选项exact,approx,auto\n",
    "          'seed': 0,\n",
    "          'nthread': 12  # 并行线程数\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = xgb.train(params, train_dmatrix, num_boost_round=1000, evals=[\n",
    "                  (test_dmatrix, 'test')], early_stopping_rounds=100)\n",
    "\n",
    "# 预测测试集\n",
    "xgbyhat = model.predict(test_dmatrix, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "# 绘图\n",
    "plt.plot(xgbyhat, label='xgb_predict')\n",
    "# plt.plot(ARM_yhat, label='ARM_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RMSE=%.4f' % np.sqrt(mean_squared_error(\n",
    "    test_m[:, -1], xgbyhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用支持向量机进行预测\n",
    "from sklearn.svm import SVR\n",
    "# 将数据格式转换成DMatrix格式\n",
    "train_dmatrix = xgb.DMatrix(data=train_m[:, :-1], label=train_m[:, -1])\n",
    "test_dmatrix = xgb.DMatrix(data=test_m[:, :-1], label=test_m[:, -1])\n",
    "\n",
    "# 设置参数\n",
    "params = {'kernel': 'rbf',    # 核函数,可选项rbf,poly,sigmoid,linear\n",
    "          'gamma': 'auto',    # 核函数系数,可选项scale,auto\n",
    "          'C': 1.0,   # 惩罚系数\n",
    "          'epsilon': 0.1,     # 指定了支持向量机回归模型的损失函数中的ε\n",
    "          'shrinking': True,  # 是否使用启发式\n",
    "          'tol': 0.001,   # 指定了支持向量机算法停止的容忍度\n",
    "          'cache_size': 2000,  # 指定了核矩阵的缓存大小\n",
    "          'verbose': False,   # 是否启用详细输出\n",
    "          'max_iter': -1,     # 指定了最大迭代次数\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = SVR(**params)\n",
    "model.fit(train_m[:, :-1], train_m[:, -1])\n",
    "\n",
    "# 预测测试集\n",
    "svr_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    svr_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= svr_yhat[i]\n",
    "# 绘图\n",
    "plt.plot(xgbyhat, label='xgb_predict')\n",
    "plt.plot(svr_yhat, label='svr_predict')\n",
    "#plt.plot(ARM_yhat, label='ARM_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'XGB-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], xgbyhat)))\n",
    "plt.text(0, 0.4, 'SVR-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], svr_yhat)))\n",
    "#plt.text(0, 0.3, 'ARM-RMSE: %.3f' %\n",
    "         #np.sqrt(mean_squared_error(test_m[:, -1], ARM_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用随机森林进行预测\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 将数据格式转换成DMatrix格式\n",
    "train_dmatrix = xgb.DMatrix(data=train_m[:, :-1], label=train_m[:, -1])\n",
    "test_dmatrix = xgb.DMatrix(data=test_m[:, :-1], label=test_m[:, -1])\n",
    "\n",
    "# 设置参数\n",
    "params = {'n_estimators': 100,    # 森林中树的数量\n",
    "          # 分裂节点时评估准则,可选项'poisson', 'squared_error', 'absolute_error', 'friedman_mse'\n",
    "          'criterion': 'squared_error',\n",
    "          'max_depth': None,  # 树的最大深度\n",
    "          'min_samples_leaf': 1,  # 叶子节点所需的最小样本数\n",
    "          'min_weight_fraction_leaf': 0.0,    # 叶子节点所需的最小加权分数\n",
    "          'max_features': 'auto',     # 寻找最佳分割时考虑的特征数,可选项auto,sqrt,log2\n",
    "          'max_leaf_nodes': None,     # 叶子节点的最大数量\n",
    "          'min_impurity_decrease': 0.0,    # 如果节点分裂会导致杂质的减少大于或等于该值,则分裂该节点\n",
    "          'bootstrap': True,  # 是否使用bootstrap样本\n",
    "          'oob_score': False,     # 是否使用袋外样本来估计泛化精度\n",
    "          'n_jobs': None,     # 并行运行的作业数\n",
    "          'random_state': None,   # 随机种子\n",
    "          'verbose': 0,   # 是否启用详细输出\n",
    "          'warm_start': False,    # 是否使用上一次调用该类的结果然后增加新的树\n",
    "          'ccp_alpha': 0.0,   # 非负的复杂性参数\n",
    "          'max_samples': None     # 用于训练每棵树的样本数\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = RandomForestRegressor(**params)\n",
    "model.fit(train_m[:, :-1], train_m[:, -1])\n",
    "\n",
    "\n",
    "rf_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    rf_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= rf_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "plt.plot(xgbyhat, label='xgb_predict')\n",
    "plt.plot(svr_yhat, label='svr_predict')\n",
    "plt.plot(rf_yhat, label='rf_predict')\n",
    "# plt.plot(ARM_yhat, label='ARM_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'XGB-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], xgbyhat)))\n",
    "plt.text(0, 0.4, 'SVR-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], svr_yhat)))\n",
    "plt.text(0, 0.3, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "# plt.text(0, 0.2, 'ARM-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], ARM_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用KNN进行预测\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# 将数据格式转换成DMatrix格式\n",
    "train_dmatrix = xgb.DMatrix(data=train_m[:, :-1], label=train_m[:, -1])\n",
    "test_dmatrix = xgb.DMatrix(data=test_m[:, :-1], label=test_m[:, -1])\n",
    "\n",
    "# 设置参数\n",
    "params = {'n_neighbors': 5,   # 邻居数\n",
    "          'weights': 'distance',   # 权重函数,可选项uniform,distance\n",
    "          'algorithm': 'auto',    # 计算最近邻居的算法,可选项auto,ball_tree,kd_tree,brute\n",
    "          'leaf_size': 30,    # 传递给BallTree或KDTree的叶子大小\n",
    "          'p': 2,     # 闵可夫斯基距离参数，p = 1为曼哈顿距离，p = 2为欧式距离\n",
    "          'metric': 'minkowski',  # 用于树的距离度量，可选项minkowski,manhattan,euclidean,chebyshev\n",
    "          'metric_params': None,  # 距离度量的其他关键字参数\n",
    "          'n_jobs': None  # 并行运行的作业数\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = KNeighborsRegressor(**params)\n",
    "model.fit(train_m[:, :-1], train_m[:, -1])\n",
    "\n",
    "knn_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    knn_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= knn_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(xgbyhat, label='xgb_predict')\n",
    "# plt.plot(svr_yhat, label='svr_predict')\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(knn_yhat, label='knn_predict')\n",
    "# plt.plot(ARM_yhat, label='ARM_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'XGB-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], xgbyhat)))\n",
    "plt.text(0, 0.4, 'SVR-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], svr_yhat)))\n",
    "plt.text(0, 0.3, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.2, 'KNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "# plt.text(0, 0.1, 'ARM-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], ARM_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用决策树进行预测\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 设置参数\n",
    "params = {'criterion': 'absolute_error',  # 分裂节点时评估准则,可选项'poisson', 'squared_error', 'absolute_error', 'friedman_mse'\n",
    "          'splitter': 'best',     # 分裂节点的策略,可选项'best','random'\n",
    "          'max_depth': None,  # 树的最大深度\n",
    "          'min_samples_leaf': 1,  # 叶子节点所需的最小样本数\n",
    "          'min_weight_fraction_leaf': 0.0,    # 叶子节点所需的最小加权分数\n",
    "          'max_features': None,   # 寻找最佳分割时考虑的特征数,可选项auto,sqrt,log2\n",
    "          'max_leaf_nodes': None,     # 叶子节点的最大数量\n",
    "          'min_impurity_decrease': 0.0,    # 如果节点分裂会导致杂质的减少大于或等于该值,则分裂该节点\n",
    "          'random_state': None,   # 随机种子\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = DecisionTreeRegressor(**params)\n",
    "model.fit(train_m[:, :-1], train_m[:, -1])\n",
    "\n",
    "# 预测测试集\n",
    "dt_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    dt_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= dt_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(dt_yhat, label='dt_predict')\n",
    "# plt.plot(ARM_yhat, label='ARM_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'DT-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], dt_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用线性回归进行预测\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 设置参数\n",
    "params = {'fit_intercept': True,  # 是否计算截距\n",
    "          'copy_X': True,     # 是否复制X\n",
    "          'n_jobs': None  # 并行运行的作业数\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = LinearRegression(**params)\n",
    "model.fit(train_m[:, :-1], train_m[:, -1])\n",
    "\n",
    "# 预测测试集\n",
    "lr_yhat=np.zeros((test_m.shape[0], 1))\n",
    "for i in range(test_m.shape[0]):\n",
    "    lr_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= lr_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(lr_yhat, label='lr_predict')\n",
    "# plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'LR-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], lr_yhat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用多项式回归进行预测\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 设置参数\n",
    "params = {'degree': 2,     # 多项式的次数\n",
    "          'interaction_only': False,  # 是否只包含交互项\n",
    "          'include_bias': True   # 是否包含偏差\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = Pipeline([('poly', PolynomialFeatures(**params)),\n",
    "                 ('linear', LinearRegression())])\n",
    "model.fit(train_m[:, :-1], train_m[:, -1])\n",
    "\n",
    "pr_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    pr_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= pr_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(pr_yhat, label='pr_predict')\n",
    "# plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'PR-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], pr_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用岭回归进行预测\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# 设置参数\n",
    "params = {'alpha': 1.0,   # 正则化强度\n",
    "          'fit_intercept': True,  # 是否计算截距\n",
    "          'copy_X': True,     # 是否复制X\n",
    "          'max_iter': None,   # 最大迭代次数\n",
    "          'tol': 0.001,   # 指定了支持向量机算法停止的容忍度\n",
    "          'solver': 'auto',   # 求解器,可选项auto,sag,saga,sparse_cg,lsqr,saga\n",
    "          'random_state': None    # 随机种子\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = Ridge(**params)\n",
    "model.fit(train_m[:, :-1], train_m[:, -1])\n",
    "rd_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    rd_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= rd_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(rd_yhat, label='rd_predict')\n",
    "# plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'RD-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rd_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用LSTM进行预测\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# 设置参数\n",
    "params = {'units': 50,    # 输出空间的维度\n",
    "          # 激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "          'activation': 'tanh',\n",
    "          # 递归层激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "          'recurrent_activation': 'sigmoid',\n",
    "          'use_bias': True,   # 是否使用偏差\n",
    "          # 权重矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'kernel_initializer': 'glorot_uniform',\n",
    "          # 递归矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'recurrent_initializer': 'orthogonal',\n",
    "          # 偏差向量的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'bias_initializer': 'zeros',\n",
    "          'unit_forget_bias': True,   # 是否添加1到偏差\n",
    "          'dropout': 0.0,     # 输入单元的dropout比例\n",
    "          'recurrent_dropout': 0.0,   # 递归单元的dropout比例\n",
    "          'implementation': 1,    # 实现模式,可选项1,2\n",
    "          'return_sequences': False,  # 是否返回全部输出序列\n",
    "          'return_state': False,  # 是否返回最后一个状态\n",
    "          'go_backwards': False,  # 是否反向处理输入序列\n",
    "          'stateful': False,  # 是否在批次间保持递归状态\n",
    "          'unroll': False    # 是否展开递归层\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = Sequential() \n",
    "model.add(LSTM(**params, input_shape=( windows,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(train_m[:, :-1], train_m[:, -1],\n",
    "          epochs=100, batch_size=64, verbose=2)\n",
    "lstm_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    lstm_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= lstm_yhat[i]\n",
    "\n",
    "# 绘图 \n",
    "plt.plot(lstm_yhat, label='lstm_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'LSTM-RMSE: %.3f' %\n",
    "            np.sqrt(mean_squared_error(test_m[:, -1], lstm_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用GRU进行预测\n",
    "from keras.layers import GRU\n",
    "\n",
    "# 设置参数\n",
    "params = {'units': 50,    # 输出空间的维度\n",
    "          # 激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "          'activation': 'tanh',\n",
    "          # 递归层激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "          'recurrent_activation': 'sigmoid',\n",
    "          'use_bias': True,   # 是否使用偏差\n",
    "          # 权重矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'kernel_initializer': 'zero',\n",
    "          # 递归矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'recurrent_initializer': 'zero',\n",
    "          # 偏差向量的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'bias_initializer': 'zeros',\n",
    "          'kernel_regularizer': None,     # 权重矩阵的正则化方法,可选项l1,l2,l1_l2\n",
    "          'recurrent_regularizer': None,  # 递归矩阵的正则化方法,可选项l1,l2,l1_l2\n",
    "          'bias_regularizer': None,   # 偏差向量的正则化方法,可选项l1,l2,l1_l2\n",
    "          'activity_regularizer': None,   # 输出的正则化方法,可选项l1,l2,l1_l2\n",
    "          'kernel_constraint': None,  # 权重矩阵的约束方法,可选项max_norm,non_neg\n",
    "          'recurrent_constraint': None,   # 递归矩阵的约束方法,可选项max_norm,non_neg\n",
    "          'bias_constraint': None,    # 偏差向量的约束方法,可选项max_norm,non_neg\n",
    "          'dropout': 0.0,     # 输入单元的dropout比例\n",
    "          'recurrent_dropout': 0.0,   # 递归单元的dropout比例\n",
    "          'implementation': 1,    # 实现模式,可选项1,2\n",
    "          'return_sequences': False,  # 是否返回全部输出序列\n",
    "          'return_state': False,  # 是否返回最后一个状态\n",
    "          'go_backwards': False,  # 是否反向处理输入序列\n",
    "          'stateful': False,  # 是否在批次间保持递归状态\n",
    "          'unroll': False    # 是否展开递归层\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = Sequential()\n",
    "model.add(GRU(**params, input_shape=(train_m.shape[1]-1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(train_m[:, :-1], train_m[:, -1],\n",
    "          epochs=100, batch_size=64, verbose=2)\n",
    "gru_yhat = np.zeros((test_m.shape[0], 1))\n",
    "# 预测测试集\n",
    "for i in range(test_m.shape[0]):\n",
    "    gru_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= gru_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(gru_yhat, label='gru_predict')\n",
    "#plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'GRU-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], gru_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.045*scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用CNN进行预测\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# 设置参数\n",
    "params = {'filters': 64,   # 卷积核的数量\n",
    "          'kernel_size': 3,   # 卷积核的大小\n",
    "          'strides': 1,   # 卷积核的步长\n",
    "          'padding': 'same',  # 填充方式,可选项valid,same\n",
    "          'data_format': 'channels_last',     # 输入数据的格式,可选项channels_last,channels_first\n",
    "          'dilation_rate': 1,     # 卷积核的膨胀率\n",
    "          # 激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "          'activation': 'relu',\n",
    "          'use_bias': True,   # 是否使用偏差\n",
    "          # 权重矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'kernel_initializer': 'glorot_uniform',\n",
    "          # 偏差向量的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "          'bias_initializer': 'zeros'\n",
    "          }\n",
    "\n",
    "# 训练模型\n",
    "model = Sequential()\n",
    "model.add(Conv1D(**params, input_shape=(train_m.shape[1]-1, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(train_m[:, :-1], train_m[:, -1],\n",
    "          epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# 预测测试集\n",
    "cnn_yhat=np.zeros((test_m.shape[0], 1))\n",
    "for i in range(test_m.shape[0]):\n",
    "    cnn_yhat[i] = model.predict(test_m[i:i+1, :-1].reshape(1, -1))\n",
    "    test_m[i+1:i+2, -2:-1]= cnn_yhat[i]\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(cnn_yhat, label='cnn_predict')\n",
    "plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'CNN-RMSE: %.3f' %\n",
    "         np.sqrt(mean_squared_error(test_m[:, -1], cnn_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用RNN进行预测 \n",
    "from keras.layers import SimpleRNN\n",
    "\n",
    "# 设置参数\n",
    "params = {'units': 50,    # 输出空间的维度\n",
    "            # 激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "            'activation': 'tanh',\n",
    "            'use_bias': True,   # 是否使用偏差\n",
    "            'dropout': 0.0,     # 输入单元的dropout比例\n",
    "            'recurrent_dropout': 0.0,   # 递归单元的dropout比例\n",
    "            'return_sequences': False,  # 是否返回全部输出序列\n",
    "            'return_state': False,  # 是否返回最后一个状态\n",
    "            'go_backwards': False,  # 是否反向处理输入序列\n",
    "            'stateful': False,  # 是否在批次间保持递归状态\n",
    "            'unroll': False    # 是否展开递归层\n",
    "            }\n",
    "\n",
    "# 训练模型\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(**params, input_shape=(train_m.shape[1]-1, 1)))\n",
    "model.add(Dense(1)) \n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(train_m[:, :-1], train_m[:, -1],\n",
    "            epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# 预测测试集\n",
    "rnn_yhat = model.predict(test_m[:, :-1]) \n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(rnn_yhat, label='rnn_predict')\n",
    "plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'RNN-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], rnn_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用BiLSTM进行预测 \n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# 设置参数\n",
    "params = {'units': 50,    # 输出空间的维度\n",
    "            # 激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "            'activation': 'tanh',\n",
    "            # 递归层激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "            'recurrent_activation': 'sigmoid',\n",
    "            'use_bias': True,   # 是否使用偏差\n",
    "            # 权重矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "            'kernel_initializer': 'glorot_uniform',\n",
    "            # 递归矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "            'recurrent_initializer': 'orthogonal',\n",
    "            # 偏差向量的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "            'bias_initializer': 'zeros',\n",
    "            'unit_forget_bias': True,   # 是否添加1到偏差\n",
    "            'dropout': 0.0,     # 输入单元的dropout比例\n",
    "            'recurrent_dropout': 0.0,   # 递归单元的dropout比例\n",
    "            'implementation': 1,    # 实现模式,可选项1,2\n",
    "            'return_sequences': False,  # 是否返回全部输出序列\n",
    "            'return_state': False,  # 是否返回最后一个状态\n",
    "            'go_backwards': False,  # 是否反向处理输入序列\n",
    "            'stateful': False,  # 是否在批次间保持递归状态\n",
    "            'unroll': False    # 是否展开递归层\n",
    "            }\n",
    "\n",
    "# 训练模型\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(**params), input_shape=(train_m.shape[1]-1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(train_m[:, :-1], train_m[:, -1],\n",
    "            epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# 预测测试集\n",
    "bilstm_yhat = model.predict(test_m[:, :-1])\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(bilstm_yhat, label='bilstm_predict')\n",
    "#plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'BiLSTM-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], bilstm_yhat)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用BiGRU进行预测\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "# 设置参数\n",
    "params = {'units': 50,    # 输出空间的维度\n",
    "            # 激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "            'activation': 'tanh',\n",
    "            # 递归层激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "            'recurrent_activation': 'sigmoid',\n",
    "            'use_bias': True,   # 是否使用偏差\n",
    "            'dropout': 0.0,     # 输入单元的dropout比例\n",
    "            'recurrent_dropout': 0.0,   # 递归单元的dropout比例\n",
    "            'implementation': 1,    # 实现模式,可选项1,2\n",
    "            'return_sequences': False,  # 是否返回全部输出序列\n",
    "            'return_state': False,  # 是否返回最后一个状态\n",
    "            'go_backwards': False,  # 是否反向处理输入序列\n",
    "            'stateful': False,  # 是否在批次间保持递归状态\n",
    "            'unroll': False    # 是否展开递归层\n",
    "            }\n",
    "\n",
    "# 训练模型\n",
    "model = Sequential() \n",
    "model.add(Bidirectional(GRU(**params), input_shape=(train_m.shape[1]-1, 1))) \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(train_m[:, :-1], train_m[:, -1],\n",
    "            epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# 预测测试集\n",
    "bigru_yhat = model.predict(test_m[:, :-1])\n",
    "\n",
    "# 绘图\n",
    "# plt.plot(rf_yhat, label='rf_predict')\n",
    "plt.plot(bigru_yhat, label='bigru_predict')\n",
    "#plt.plot(knn_yhat, label='knn_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'RF-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], rf_yhat)))\n",
    "plt.text(0, 0.4, 'KNN-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], knn_yhat)))\n",
    "plt.text(0, 0.3, 'BiGRU-RMSE: %.3f' % np.sqrt(mean_squared_error(test_m[:, -1], bigru_yhat)))\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用ARIMA进行预测，再用BiLSTM预测残差，最后将预测值相加\n",
    "model = ARIMA(train, order=(3, 3, 30))\n",
    "\n",
    "model_fit = model.fit()\n",
    "\n",
    "# 预测测试集\n",
    "ARM_yhat = model_fit.predict(1, len(train), typ='levels')\n",
    "\n",
    "\n",
    "# 计算残差\n",
    "residual = train[:, -1] - ARM_yhat\n",
    "\n",
    "residual_m = np.zeros((residual.size-windows, windows+1))\n",
    "for i in range(residual.size-windows):    # 生成矩阵\n",
    "    residual_m[i] = residual[i:i+windows+1].T\n",
    "\n",
    "\n",
    "# 设置参数\n",
    "params = {'units': 50,    # 输出空间的维度\n",
    "            # 激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "            'activation': 'tanh',\n",
    "            # 递归层激活函数,可选项softmax,softplus,softsign,relu,tanh,sigmoid,hard_sigmoid,linear\n",
    "            'recurrent_activation': 'sigmoid',\n",
    "            'use_bias': True,   # 是否使用偏差\n",
    "            # 权重矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "            'kernel_initializer': 'glorot_uniform',\n",
    "            # 递归矩阵的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "            'recurrent_initializer': 'orthogonal',\n",
    "            # 偏差向量的初始化方法,可选项glorot_uniform,lecun_uniform,normal,orthogonal,zero,one\n",
    "            'bias_initializer': 'zeros',\n",
    "            'unit_forget_bias': True,   # 是否添加1到偏差\n",
    "            'dropout': 0.0,     # 输入单元的dropout比例\n",
    "            'recurrent_dropout': 0.0,   # 递归单元的dropout比例\n",
    "            'implementation': 1,    # 实现模式,可选项1,2\n",
    "            'return_sequences': False,  # 是否返回全部输出序列\n",
    "            'return_state': False,  # 是否返回最后一个状态\n",
    "            'go_backwards': False,  # 是否反向处理输入序列\n",
    "            'stateful': False,  # 是否在批次间保持递归状态\n",
    "            'unroll': False    # 是否展开递归层\n",
    "            }\n",
    "\n",
    "# 训练模型\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(**params), input_shape=(residual_m.shape[1]-1, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(residual_m[:, :-1], residual_m[:, -1],\n",
    "          epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# 预测测试集\n",
    "\n",
    "BiLSTM_yhat = np.zeros((test_m.shape[0], 1))\n",
    "\n",
    "ARM_ypre=model_fit.predict(len(train)+1, len(train)+len(test)-1, typ='levels')\n",
    "\n",
    "for i in range(test_m.shape[0]):\n",
    "    BiLSTM_yhat[i] = model.predict(residual_m[i:i+1, :-1].reshape(1, -1))\n",
    "    residual_m[i+1:i+2, -2:-1]= BiLSTM_yhat[i]\n",
    "\n",
    "Total_yhat=ARM_ypre+BiLSTM_yhat.reshape(-1)\n",
    "\n",
    "# 绘图 \n",
    "plt.plot(Total_yhat, label='Total_predict')\n",
    "plt.plot(test_m[:, -1], label='true')\n",
    "plt.text(0, 0.5, 'Total-RMSE: %.3f' %\n",
    "            np.sqrt(mean_squared_error(test_m[:, -1], Total_yhat)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
